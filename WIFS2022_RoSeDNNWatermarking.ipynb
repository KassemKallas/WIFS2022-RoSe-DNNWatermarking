{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# tensorflow model optimization for weight quantization"
      ],
      "metadata": {
        "id": "KsGySY5K8TBS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V55I8pDcUang"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow-model-optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "Wb6a4pUI86-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "import hashlib\n",
        "import math\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist, fashion_mnist, cifar10\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import pathlib\n",
        "import numpy as np\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping, LearningRateScheduler\n",
        "import tempfile\n",
        "import zipfile\n",
        "import os\n",
        "import h5py\n",
        "import glob\n",
        "from numpy import linalg as LA\n",
        "from scipy.stats import rankdata\n",
        "from shutil import copyfile, move\n",
        "from PIL import Image\n",
        "import random\n",
        "import cv2\n",
        "import tensorflow_model_optimization as tfmot\n",
        "import tensorboard\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications.vgg19 import VGG19"
      ],
      "metadata": {
        "id": "dPHTzbUB8-I6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simulation Parameters"
      ],
      "metadata": {
        "id": "6DrcRWxnAIOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = 'cifar10' #the dataset for the experiment, OPTIONS: mnist, fashionmnist, cifar10 and imagenet\n",
        "\n",
        "FT_portion = 0.1 # how much from the original dataset we preserve for fine-tuning\n",
        "\n",
        "nb_classes = 10\n",
        "\n",
        "if dataset == 'mnist' or dataset == 'fashionmnist':\n",
        "    input_shape = (28, 28, 1) # the input volume shape for the CNN\n",
        "    epochs = 100\n",
        "else:\n",
        "    input_shape = (32, 32, 3)\n",
        "    epochs = 200\n",
        "\n",
        "batch_size = 64 #training batch size\n",
        "\n",
        "batch_size_FT = 64 # fine tuning batch size\n",
        "\n",
        "epochs_FT = 30 # epochs FT\n",
        "\n",
        "pruning_trials = 50 #how many experiments on random weights pruning for each k\n",
        "\n",
        "lr_FT = 1e-5 # learning rate for finetuning/pruning\n",
        "\n",
        "val_split_training = 0.1 # validation set for training\n",
        "\n",
        "val_split_FT = 0.1 # validation set for finetuning\n",
        "\n",
        "Freeze_CNN = False # to freeze or not the feature extractors at fine-tuning\n",
        "\n",
        "base_dir = './' #base directory where to create dirs and save results\n",
        "\n",
        "hash_output_size = 160 # 160 for SHA1, 256 for SHA256, 512 for SHA512\n",
        "\n",
        "ks = [0.0, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 0.97, 0.99] #weight pruning rates\n",
        "\n",
        "JPEG_QF = [55, 60, 65, 70, 75, 80, 85, 90, 95, 100] #JPEG QUALITY FACTORS USED\n",
        "\n",
        "learn_rate = 0.001 #used in case of cifar10 and imagenet"
      ],
      "metadata": {
        "id": "c40tPGQ1AEtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "emUN683Q8chc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**copy folder and its content to a destination**"
      ],
      "metadata": {
        "id": "h0M57S_0zlHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def copy_and_overwrite(from_path, to_path):\n",
        "    if os.path.exists(to_path):\n",
        "        shutil.rmtree(to_path)\n",
        "    shutil.copytree(from_path, to_path)"
      ],
      "metadata": {
        "id": "oZG88M7ozent"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Confusion Matrix**"
      ],
      "metadata": {
        "id": "aA6yHlV281Nc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xh5N_3qLUr17"
      },
      "outputs": [],
      "source": [
        "def make_confusion_matrix(cf, savePath, saveName,\n",
        "                          group_names=None,\n",
        "                          categories='auto',\n",
        "                          count=True,\n",
        "                          percent=True,\n",
        "                          cbar=True,\n",
        "                          xyticks=True,\n",
        "                          xyplotlabels=True,\n",
        "                          sum_stats=True,\n",
        "                          figsize=None,\n",
        "                          cmap='Blues',\n",
        "                          title=None):\n",
        "    '''\n",
        "    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    cf:            confusion matrix to be passed in\n",
        "\n",
        "    group_names:   List of strings that represent the labels row by row to be shown in each square.\n",
        "\n",
        "    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'\n",
        "\n",
        "    count:         If True, show the raw number in the confusion matrix. Default is True.\n",
        "\n",
        "    normalize:     If True, show the proportions for each category. Default is True.\n",
        "\n",
        "    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.\n",
        "                   Default is True.\n",
        "\n",
        "    xyticks:       If True, show x and y ticks. Default is True.\n",
        "\n",
        "    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.\n",
        "\n",
        "    sum_stats:     If True, display summary statistics below the figure. Default is True.\n",
        "\n",
        "    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.\n",
        "\n",
        "    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'\n",
        "                   See http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "\n",
        "    title:         Title for the heatmap. Default is None.\n",
        "\n",
        "    savePath:      where to save the plot\n",
        "\n",
        "    '''\n",
        "\n",
        "    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n",
        "    blanks = ['' for i in range(cf.size)]\n",
        "\n",
        "    if group_names and len(group_names) == cf.size:\n",
        "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
        "    else:\n",
        "        group_labels = blanks\n",
        "\n",
        "    if count:\n",
        "        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
        "    else:\n",
        "        group_counts = blanks\n",
        "\n",
        "    if percent:\n",
        "        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten() / np.sum(cf)]\n",
        "    else:\n",
        "        group_percentages = blanks\n",
        "\n",
        "    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels, group_counts, group_percentages)]\n",
        "    box_labels = np.asarray(box_labels).reshape(cf.shape[0], cf.shape[1])\n",
        "\n",
        "    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n",
        "    if sum_stats:\n",
        "        # Accuracy is sum of diagonal divided by total observations\n",
        "        accuracy = np.trace(cf) / float(np.sum(cf))\n",
        "\n",
        "        # if it is a binary confusion matrix, show some more stats\n",
        "        if len(cf) == 2:\n",
        "            # Metrics for Binary Confusion Matrices\n",
        "            precision = cf[1, 1] / sum(cf[:, 1])\n",
        "            recall = cf[1, 1] / sum(cf[1, :])\n",
        "            f1_score = 2 * precision * recall / (precision + recall)\n",
        "            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\n",
        "                accuracy, precision, recall, f1_score)\n",
        "        else:\n",
        "            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n",
        "    else:\n",
        "        stats_text = \"\"\n",
        "\n",
        "    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n",
        "    if figsize == None:\n",
        "        # Get default figure size if not set\n",
        "        figsize = plt.rcParams.get('figure.figsize')\n",
        "\n",
        "    if xyticks == False:\n",
        "        # Do not show categories if xyticks is False\n",
        "        categories = False\n",
        "\n",
        "    # MAKE THE HEATMAP VISUALIZATION\n",
        "    plt.figure(figsize=figsize)\n",
        "    sns.heatmap(cf, annot=box_labels, fmt=\"\", cmap=cmap, cbar=cbar, xticklabels=categories, yticklabels=categories)\n",
        "\n",
        "    if xyplotlabels:\n",
        "        plt.ylabel('True label')\n",
        "        plt.xlabel('Predicted label' + stats_text)\n",
        "    else:\n",
        "        plt.xlabel(stats_text)\n",
        "\n",
        "    if title:\n",
        "        plt.title(title)\n",
        "\n",
        "    plt.savefig(Path(savePath) / (str(saveName) + '.jpg'))\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm, save_path, save_name, categories_digits):\n",
        "    make_confusion_matrix(cf=cm, savePath=save_path, saveName=save_name,\n",
        "                          group_names=None,\n",
        "                          categories=categories_digits,\n",
        "                          count=True,\n",
        "                          percent=True,\n",
        "                          cbar=True,\n",
        "                          xyticks=True,\n",
        "                          xyplotlabels=True,\n",
        "                          sum_stats=True,\n",
        "                          figsize=(12, 8),\n",
        "                          cmap='Blues',\n",
        "                          title=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function bool2int(x): convert binary to integer**"
      ],
      "metadata": {
        "id": "2GJlRUqe9Lde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bool2int(x):\n",
        "    y = 0\n",
        "    for i, j in enumerate(x):\n",
        "        y += j << i\n",
        "    return y"
      ],
      "metadata": {
        "id": "rjt5PxWi98B4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**flat_N_images(trainX, index_imgs): flat N images and return them plus their binary vector**"
      ],
      "metadata": {
        "id": "rsIg7u9A-ID0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def flat_N_images(trainX, index_imgs):\n",
        "    all_images_flat_array = trainX[index_imgs].flatten()\n",
        "    all_images_flat_binary_array = np.array(all_images_flat_array).clip(max=1)\n",
        "\n",
        "    return all_images_flat_array, all_images_flat_binary_array"
      ],
      "metadata": {
        "id": "2r5GfYc7-T5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hash Functions: SHA1, SHA256, SHA512**"
      ],
      "metadata": {
        "id": "TbzIeFFg-U_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hash_functionSHA1(s):\n",
        "    hashcode = hashlib.sha1(\n",
        "        s.encode('utf-8')).hexdigest()\n",
        "    padded_binary = bin(int(hashcode, 16))[2:].zfill(len(hashcode) * 4)\n",
        "    if len(padded_binary) < 160:\n",
        "        print(len(padded_binary))\n",
        "\n",
        "    binary_array_result = np.array([int(padded_binary[x]) for x in range(len(padded_binary))])\n",
        "    return binary_array_result, hashcode\n",
        "\n",
        "def hash_functionSHA256(s):\n",
        "    hashcode = hashlib.sha256(\n",
        "        s.encode('utf-8')).hexdigest()\n",
        "    padded_binary = bin(int(hashcode, 16))[2:].zfill(len(hashcode) * 4)\n",
        "    if len(padded_binary) < 256:\n",
        "        print(len(padded_binary))\n",
        "\n",
        "    binary_array_result = np.array([int(padded_binary[x]) for x in range(len(padded_binary))])\n",
        "    return binary_array_result, hashcode\n",
        "\n",
        "def hash_functionSHA512(s):\n",
        "    hashcode = hashlib.sha512(\n",
        "        s.encode('utf-8')).hexdigest()\n",
        "    padded_binary = bin(int(hashcode, 16))[2:].zfill(len(hashcode) * 4)\n",
        "    if len(padded_binary) < 512:\n",
        "        print(len(padded_binary))\n",
        "\n",
        "    binary_array_result = np.array([int(padded_binary[x]) for x in range(len(padded_binary))])\n",
        "    return binary_array_result, hashcode"
      ],
      "metadata": {
        "id": "mI8YRaoX-cvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MAP(): take the hash output and return the key labels**"
      ],
      "metadata": {
        "id": "FDawEiSc-iCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MAP(hash_output, nb_classes):\n",
        "  nb_bits_per_class = int(math.ceil(math.log2(nb_classes)))\n",
        "  arr_dim = len(hash_output)//nb_bits_per_class\n",
        "  labels = np.zeros((arr_dim,))\n",
        "  for i in range(hash_output.shape[0]//nb_bits_per_class):\n",
        "    tmp = int(bool2int(hash_output[i*nb_bits_per_class:(i+1)*nb_bits_per_class]))\n",
        "    if tmp >= nb_classes:\n",
        "      labels[i] = tmp%nb_classes\n",
        "    else:\n",
        "      labels[i] = tmp\n",
        "  return labels.astype(\"int\")"
      ],
      "metadata": {
        "id": "yq2w0-A3-p15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GenerateKeyLabels(): Encapsulates all the functions above. Take the secret key, training set and image indeces and return the key labels**"
      ],
      "metadata": {
        "id": "OqMSQp8V_W4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def GenerateKeyLabels(trainX, img_index, sec_key, nb_classes, hash_output_size): \n",
        "    res_flat_str, res_flat_binary = flat_N_images(trainX, img_index)\n",
        "\n",
        "    res_flat_str = str(trainX[img_index]).lstrip('[').rstrip(']')\n",
        "    sec_key_str = str(sec_key).lstrip('[').rstrip(']')\n",
        "\n",
        "    res_img_key = [chr(ord(a) ^ ord(b)) for a,b in zip(res_flat_str, sec_key_str)]\n",
        "    res_img_key = \"\".join(res_img_key)\n",
        "    res_str = str(res_img_key)\n",
        "\n",
        "\n",
        "    if hash_output_size == 160:\n",
        "        binary_hashout, hashout = hash_functionSHA1(res_str)\n",
        "    elif hash_output_size == 256:\n",
        "        binary_hashout, hashout = hash_functionSHA256(res_str)\n",
        "    else:\n",
        "        binary_hashout, hashout = hash_functionSHA512(res_str)\n",
        "    labels = MAP(binary_hashout, nb_classes)\n",
        "\n",
        "    return labels"
      ],
      "metadata": {
        "id": "c3hZ047V8p0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**run_tflite_model(): Helper function to run inference on a TFLite model when applying weight quantization methods**"
      ],
      "metadata": {
        "id": "UScrVsJY_vot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_tflite_model(tflite_file, dsX, dsY, index_imgs):\n",
        "\n",
        "    # Initialize the interpreter\n",
        "    interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    input_details = interpreter.get_input_details()[0]\n",
        "    output_details = interpreter.get_output_details()[0]\n",
        "\n",
        "    predictions = np.zeros((len(index_imgs),), dtype=int)\n",
        "    for i, test_image_index in enumerate(index_imgs):\n",
        "        test_image = dsX[test_image_index,]\n",
        "        test_label = dsY[test_image_index,]\n",
        "\n",
        "        if input_details['dtype'] == np.uint8:\n",
        "            input_scale, input_zero_point = input_details[\"quantization\"]\n",
        "            test_image = test_image / input_scale + input_zero_point\n",
        "\n",
        "        test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n",
        "        interpreter.set_tensor(input_details[\"index\"], test_image)\n",
        "        interpreter.invoke()\n",
        "        output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
        "\n",
        "        predictions[i] = output.argmax()\n",
        "\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "S9v_P8Yu8taj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normalize Data and Generate One hot label version**"
      ],
      "metadata": {
        "id": "YtcjPyzzJamo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Normalize_and_OneHot(x,y, nb_classes):\n",
        "    x = x.astype(\"float32\") / 255\n",
        "    if x.shape.__len__() == 3: # expand greyscale, not RGB\n",
        "        x = np.expand_dims(x, -1)\n",
        "    y = to_categorical(y, num_classes = nb_classes)\n",
        "    return x,y"
      ],
      "metadata": {
        "id": "1cj7wqZAJA0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DNN Model**"
      ],
      "metadata": {
        "id": "9ykkgJ5dCG7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_mnist():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Conv2D(64, kernel_size=5, activation='relu', input_shape=input_shape))\n",
        "    model.add(tf.keras.layers.MaxPool2D())\n",
        "    model.add(tf.keras.layers.Conv2D(128, kernel_size=5, activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPool2D())\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(nb_classes, activation='softmax'))\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "def model_fashionmnist():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Conv2D(64,kernel_size=5,activation='relu',input_shape=input_shape))\n",
        "    model.add(tf.keras.layers.MaxPool2D())\n",
        "    model.add(tf.keras.layers.Conv2D(128,kernel_size=5,activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPool2D())\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "    model.add(tf.keras.layers.Dense(nb_classes, activation='softmax'))\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "def model_cifar10():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "    model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "    model.add(tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "    model.add(tf.keras.layers.Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "    model.add(tf.keras.layers.Dense(nb_classes, activation='softmax'))\n",
        "    opt = SGD(lr=learn_rate, momentum=0.9)\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def model_imagenet():\n",
        "    base_model = VGG19(include_top=False,weights='imagenet',input_shape=input_shape,classes=nb_classes)\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(base_model)\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(1024,activation=('relu')))\n",
        "    model.add(tf.keras.layers.Dense(512,activation=('relu')))\n",
        "    model.add(tf.keras.layers.Dense(nb_classes,activation=('softmax'))) #This is the classification layer\n",
        "    sgd=SGD(learning_rate=learn_rate,momentum=.9,nesterov=False)\n",
        "    model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "sXRNLX9BCKlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot and Save Training History**"
      ],
      "metadata": {
        "id": "GJTWEaSuEHnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def PlotTrainingHistory(res_dir, history): \n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'val'], loc='lower right')\n",
        "    plt.grid()\n",
        "    plt.savefig(os.path.join(res_dir, 'accuracy_plot_model.jpg'))\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'val'], loc='upper right')\n",
        "    plt.grid()\n",
        "    plt.savefig(os.path.join(res_dir, 'loss_plot_model.jpg'))\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "qi__wZhqEMG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Weights pruning**"
      ],
      "metadata": {
        "id": "vZexInlRRFlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def weight_pruning(modelPruning, pruning_rate):\n",
        "    for idx, layer in enumerate(modelPruning.layers):\n",
        "        #print(layer.name, layer.trainable)\n",
        "\n",
        "        layer_weights = modelPruning.get_layer(name=layer.name).get_weights()\n",
        "\n",
        "        if np.array(layer_weights).shape[0] == 0:\n",
        "            weight = np.array(layer_weights)\n",
        "        else:\n",
        "            weight = np.array(layer_weights[0])\n",
        "\n",
        "        indices = np.random.choice(np.arange(weight.size), replace=False, size=int(weight.size * k))\n",
        "\n",
        "        weight[np.unravel_index(indices, weight.shape)] = 0\n",
        "\n",
        "        if np.array(layer_weights).shape[0] == 0:\n",
        "            layer_weights = weight\n",
        "        else:\n",
        "            layer_weights[0] = weight\n",
        "        \n",
        "        modelPruning.get_layer(name=layer.name).set_weights(layer_weights)\n",
        "    return modelPruning"
      ],
      "metadata": {
        "id": "g7s0xHRNRD-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fully connected layers pruning function**\n",
        "\n"
      ],
      "metadata": {
        "id": "r6rJt6C-wAUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pruning_FC(model_FC_prune, k):\n",
        "    for layer in filter(lambda x: 'dense' in x.name, model_FC_prune.layers):\n",
        "        weights_shape, bias_shape = map(lambda x: x.shape, layer.get_weights())\n",
        "        pruned_weights = np.copy(np.array(layer.get_weights()[0]))\n",
        "        pruned_bias = np.copy(np.array(layer.get_weights()[1]))\n",
        "\n",
        "        indices = np.random.choice(pruned_weights.shape[1]*pruned_weights.shape[0],\n",
        "                                    replace=False, size=int(pruned_weights.shape[1]*pruned_weights.shape[0]*k))\n",
        "        pruned_weights[np.unravel_index(indices, pruned_weights.shape)] = 0\n",
        "\n",
        "        layer.set_weights([pruned_weights, pruned_bias])\n",
        "    return model_FC_prune"
      ],
      "metadata": {
        "id": "Fol0nnQ2v_w-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model"
      ],
      "metadata": {
        "id": "okSn-4-7D7tg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Preparation**"
      ],
      "metadata": {
        "id": "rLJpkNCbEQl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(1)\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "res_dir = os.path.join(base_dir, str(hash_output_size))\n",
        "isExist = os.path.exists(res_dir)\n",
        "if not isExist:\n",
        "    os.mkdir(res_dir)\n",
        "\n",
        "\n",
        "#Create text file to write all results and info needed\n",
        "txt_file_results_Path = os.path.join(res_dir, 'results_Hash_' + str(hash_output_size) +'.txt')\n",
        "txt_file_results = open(txt_file_results_Path, 'w')\n",
        "\n",
        "\n",
        "#################################################################################################################\n",
        "###################### Data preparation #########################################################################\n",
        "#################################################################################################################\n",
        "\n",
        "#Download the dataset\n",
        "if dataset == 'mnist':\n",
        "    (x_train_all, y_train_all_base), (x_test_all, y_test_all_base) = tf.keras.datasets.mnist.load_data()\n",
        "elif dataset == 'fashionmnist':\n",
        "    (x_train_all, y_train_all_base), (x_test_all, y_test_all_base) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "elif dataset == 'cifar10':\n",
        "    (x_train_all, y_train_all_base), (x_test_all, y_test_all_base) = tf.keras.datasets.cifar10.load_data()\n",
        "else:\n",
        "    (x_train_all, y_train_all_base), (x_test_all, y_test_all_base) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "#Copy the labels to avoid variable update in numpy\n",
        "y_train_all = np.copy(y_train_all_base)\n",
        "y_test_all = np.copy(y_test_all_base)\n",
        "\n",
        "\n",
        "#SPLIT the dataset for finetuning and training\n",
        "x_train, x_train_FT, y_train, y_train_FT = train_test_split(x_train_all, y_train_all, \n",
        "                                                            test_size=FT_portion, shuffle=True, random_state=42)\n",
        "\n",
        "x_test, x_test_FT, y_test, y_test_FT = train_test_split(x_test_all, y_test_all, \n",
        "                                                            test_size=FT_portion, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLb_p48WEBvw",
        "outputId": "d2418e31-1195-4b65-c698-61da187ca886"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "170508288/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Key image-label pairs injection: DNN watermark generation**"
      ],
      "metadata": {
        "id": "1DPecQM1EcHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#################################################################################################################\n",
        "###################### Key image-label pairs injection ##########################################################\n",
        "#################################################################################################################\n",
        "#Generate Key Image-Label Pairs and Save the key indeces into a text file\n",
        "bits_per_class = int(math.ceil(math.log2(nb_classes)))\n",
        "nb_images = hash_output_size // bits_per_class\n",
        "\n",
        "#Defender secret info\n",
        "sec_key = np.random.randint(2, size=(hash_output_size,)).astype(\"uint8\") #secret key k_{sec}\n",
        "index_imgs = [random.randint(0, x_train.shape[0] - 1) for p in range(0, nb_images)]  # indeces of Key Images\n",
        "\n",
        "#Generate the key labels and inject them back into the dataset labels\n",
        "Y_h = GenerateKeyLabels(x_train, index_imgs, sec_key, nb_classes, hash_output_size)\n",
        "Y_h = Y_h.astype(np.uint8)\n",
        "\n",
        "if dataset == 'mnist' or dataset == 'fashionmnist':\n",
        "    y_train[index_imgs] = Y_h[:]\n",
        "else:\n",
        "    y_train[index_imgs] = Y_h[:].reshape((Y_h.shape[0],1))\n",
        "\n",
        "txt_file_results.write(\"The Key Images indices from the Training Dataset\" + \"\\n\")\n",
        "txt_file_results.write(str(index_imgs) + '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KXBdeT5EhD0",
        "outputId": "b2a6481f-77e3-4a06-86e4-a52b538f0845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "267"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normalize dataset and One hot encoding the labels**"
      ],
      "metadata": {
        "id": "VWd_ufOTEqLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize and OneHot Encoding\n",
        "x_train_all, y_train_all = Normalize_and_OneHot(x_train_all,y_train_all, nb_classes)\n",
        "x_test_all, y_test_all = Normalize_and_OneHot(x_test_all,y_test_all, nb_classes)\n",
        "x_train, y_train = Normalize_and_OneHot(x_train,y_train, nb_classes)\n",
        "x_test, y_test = Normalize_and_OneHot(x_test,y_test, nb_classes)\n",
        "x_test_FT, y_test_FT = Normalize_and_OneHot(x_test_FT,y_test_FT, nb_classes)\n",
        "x_train_FT, y_train_FT = Normalize_and_OneHot(x_train_FT,y_train_FT, nb_classes)\n",
        "x_test_FT, y_test_FT = Normalize_and_OneHot(x_test_FT,y_test_FT, nb_classes)"
      ],
      "metadata": {
        "id": "LAGMunjgEw52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training**"
      ],
      "metadata": {
        "id": "ad6z7rQAE0Cj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a temporary log directory\n",
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "#Create a new model instance\n",
        "if dataset == 'mnist':\n",
        "    model = model_mnist()\n",
        "elif dataset == 'fashionmnist':\n",
        "    model = model_fashionmnist()\n",
        "elif dataset == 'cifar10':\n",
        "    model = model_cifar10()\n",
        "else:\n",
        "    model = model_imagenet()\n",
        "model.summary()\n",
        "\n",
        "#create a copy of the initial model before training\n",
        "_, model_file_init = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model, model_file_init, include_optimizer=False)\n",
        "\n",
        "#Training Part to Inject the key Image-Label Pairs\n",
        "model_name_call_back = os.path.join(res_dir, str(dataset) + \"-model-at_{epoch}.h5\")\n",
        "\n",
        "csv_name = os.path.join(res_dir, str(dataset) + \"-model-SHA\" + str(hash_output_size) + \".csv\")\n",
        "csv_logger = CSVLogger(csv_name)\n",
        "\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(model_name_call_back, save_best_only=False, save_freq='epoch',\n",
        "                                                        period=10), tf.keras.callbacks.TensorBoard(log_dir=logdir, profile_batch=0),\n",
        "\n",
        "callbacks_training = [model_checkpoint, csv_logger]\n",
        "\n",
        "#Perform Training\n",
        "history = model.fit(x_train, y_train, batch_size=batch_size, callbacks = callbacks_training, epochs=epochs,\n",
        "                                validation_split=val_split_training)\n",
        "\n",
        "\n",
        "#Calculate performance metrics on Trained host DNN\n",
        "score_ts = model.evaluate(x_test, y_test, verbose=0)\n",
        "txt_file_results.write('Test accuracy of the DNN model is'+'\\n')\n",
        "txt_file_results.write(str(score_ts[1])+'\\n')\n",
        "\n",
        "score_tr = model.evaluate(x_train, y_train, verbose=0)\n",
        "txt_file_results.write('Training accuracy of the DNN model is'+'\\n')\n",
        "txt_file_results.write(str(score_tr[1])+'\\n')\n",
        "\n",
        "predictions = model.predict(x_test)\n",
        "y_pred = np.argmax(predictions, axis=-1)\n",
        "y_true = np.argmax(y_test, axis=-1)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)#, labels=[1,0])\n",
        "plot_confusion_matrix(cm, res_dir, 'confusion_matrix_model_' + str(dataset),\n",
        "                        categories_digits=[\"0\",\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"])\n",
        "\n",
        "#Plot the history of Training: Accuracy and Loss\n",
        "PlotTrainingHistory(res_dir, history)\n",
        "\n",
        "#Compute the watermark recovery rate on the trained host DNN model\n",
        "predictions = model.predict(x_train[index_imgs])\n",
        "y_pred = np.argmax(predictions, axis=-1)\n",
        "equal_guesses = (y_pred == Y_h).sum()\n",
        "\n",
        "print('DNN Watermark recovery rate of Trained model ' + str(\"{0:.0f}%\".format((equal_guesses/len(Y_h))*100)))\n",
        "txt_file_results.write('DNN Watermark recovery rate of Trained model'+'\\n')\n",
        "txt_file_results.write(str(equal_guesses/len(Y_h))+'\\n')\n",
        "\n",
        "\n",
        "#Save copy of the Host DNN model for post-processings/attacks\n",
        "_, model_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model, model_file, include_optimizer=False)\n",
        "\n",
        "_, model_file_ForPruning = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model, model_file_ForPruning, include_optimizer=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBUrdni5E1s4",
        "outputId": "b0ae18eb-06c5-431b-b128-d45ed00db7c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 4, 4, 256)         295168    \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 4, 4, 256)         590080    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 2, 2, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 2, 2, 256)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               131200    \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               33024     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,339,050\n",
            "Trainable params: 1,339,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "633/633 [==============================] - 8s 11ms/step - loss: 2.2207 - accuracy: 0.1553 - val_loss: 2.0445 - val_accuracy: 0.2393\n",
            "Epoch 2/2\n",
            "633/633 [==============================] - 6s 10ms/step - loss: 1.9507 - accuracy: 0.2550 - val_loss: 1.8855 - val_accuracy: 0.2829\n",
            "DNN Watermark recovery rate of Trained model 15%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tuning"
      ],
      "metadata": {
        "id": "8F0bE0QcEDNT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fine Tuning the host DNN model\n",
        "FineTune_model = tf.keras.models.load_model(model_file)\n",
        "\n",
        "#Unfreeze/Freeze the feature extractor of the host DNN\n",
        "if Freeze_CNN == True:\n",
        "    for ix, layer in enumerate(FineTune_model.layers):\n",
        "        if isinstance(layer, tf.keras.layers.Dense):\n",
        "            layer.trainable = True\n",
        "        else:\n",
        "            layer.trainable = False\n",
        "\n",
        "#check the freezed layers\n",
        "for ix, layer in enumerate(FineTune_model.layers):\n",
        "    print(layer.name, layer.trainable)\n",
        "\n",
        "FineTune_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = lr_FT),\n",
        "                    loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "history_fine_tuning = FineTune_model.fit(x_train_FT, y_train_FT, batch_size=batch_size_FT,\n",
        "                                    epochs=epochs_FT, validation_split=0.1)\n",
        "\n",
        "#Compute TestSet accuracy on fine-tuned model \n",
        "_, fine_tuning_test_accuracy = FineTune_model.evaluate(x_test, y_test, verbose=0)\n",
        "txt_file_results.write('Test Accuracy of the Fine-Tuned model'+'\\n')\n",
        "txt_file_results.write(str(fine_tuning_test_accuracy)+'\\n')\n",
        "\n",
        "#Compute watermark recovery performance after fine-tuning\n",
        "predicted_WM_labels_finetuning = FineTune_model.predict(x_train[index_imgs])\n",
        "predicted_WM_labels_finetuning = np.argmax(predicted_WM_labels_finetuning, axis=-1)\n",
        "\n",
        "equal_guesses = (predicted_WM_labels_finetuning == Y_h).sum()\n",
        "print('DNN Watermark recovery rate of the fine-tuned model' + ' is: ' + str(\"{0:.0f}%\".format((equal_guesses/len(Y_h))*100)))\n",
        "txt_file_results.write('DNN Watermark recovery rate of Fine-Tuned model'+'\\n')\n",
        "txt_file_results.write(str(equal_guesses/len(Y_h))+'\\n')\n",
        "\n",
        "\n",
        "#Compute testset accuracy after fine-tuning\n",
        "predictions = FineTune_model.predict(x_test)\n",
        "y_pred = np.argmax(predictions, axis=-1)\n",
        "y_true = np.argmax(y_test, axis=-1)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plot_confusion_matrix(cm, res_dir, 'confusion_matrix_FineTuned_model',\n",
        "                        categories_digits=[\"0\",\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_mdS8i7EDyF",
        "outputId": "72c243b3-e47e-40d3-eeea-e16069f0a689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv2d True\n",
            "conv2d_1 True\n",
            "max_pooling2d True\n",
            "dropout True\n",
            "conv2d_2 True\n",
            "conv2d_3 True\n",
            "max_pooling2d_1 True\n",
            "dropout_1 True\n",
            "conv2d_4 True\n",
            "conv2d_5 True\n",
            "max_pooling2d_2 True\n",
            "dropout_2 True\n",
            "conv2d_6 True\n",
            "conv2d_7 True\n",
            "max_pooling2d_3 True\n",
            "dropout_3 True\n",
            "flatten True\n",
            "dense True\n",
            "dropout_4 True\n",
            "dense_1 True\n",
            "dropout_5 True\n",
            "dense_2 True\n",
            "Epoch 1/30\n",
            "71/71 [==============================] - 2s 17ms/step - loss: 1.8255 - accuracy: 0.2933 - val_loss: 1.8316 - val_accuracy: 0.2740\n",
            "Epoch 2/30\n",
            "71/71 [==============================] - 1s 10ms/step - loss: 1.8132 - accuracy: 0.3060 - val_loss: 1.8176 - val_accuracy: 0.2740\n",
            "Epoch 3/30\n",
            "71/71 [==============================] - 1s 10ms/step - loss: 1.7989 - accuracy: 0.3027 - val_loss: 1.8132 - val_accuracy: 0.2760\n",
            "Epoch 4/30\n",
            "71/71 [==============================] - 1s 10ms/step - loss: 1.7871 - accuracy: 0.3029 - val_loss: 1.8024 - val_accuracy: 0.2820\n",
            "Epoch 5/30\n",
            "71/71 [==============================] - 1s 10ms/step - loss: 1.7893 - accuracy: 0.3131 - val_loss: 1.7980 - val_accuracy: 0.2940\n",
            "Epoch 6/30\n",
            "71/71 [==============================] - 1s 10ms/step - loss: 1.7815 - accuracy: 0.3142 - val_loss: 1.7988 - val_accuracy: 0.2800\n",
            "Epoch 7/30\n",
            "71/71 [==============================] - 1s 10ms/step - loss: 1.7783 - accuracy: 0.3096 - val_loss: 1.7826 - val_accuracy: 0.2940\n",
            "Epoch 8/30\n",
            "71/71 [==============================] - 1s 10ms/step - loss: 1.7743 - accuracy: 0.3149 - val_loss: 1.7855 - val_accuracy: 0.3000\n",
            "Epoch 9/30\n",
            "71/71 [==============================] - 1s 10ms/step - loss: 1.7641 - accuracy: 0.3224 - val_loss: 1.7802 - val_accuracy: 0.2980\n",
            "Epoch 10/30\n",
            "71/71 [==============================] - 1s 10ms/step - loss: 1.7584 - accuracy: 0.3224 - val_loss: 1.7634 - val_accuracy: 0.3060\n",
            "Epoch 11/30\n",
            "71/71 [==============================] - 1s 10ms/step - loss: 1.7619 - accuracy: 0.3287 - val_loss: 1.7770 - val_accuracy: 0.2840\n",
            "Epoch 12/30\n",
            "71/71 [==============================] - 1s 10ms/step - loss: 1.7566 - accuracy: 0.3200 - val_loss: 1.7671 - val_accuracy: 0.3040\n",
            "Epoch 13/30\n",
            "71/71 [==============================] - 1s 10ms/step - loss: 1.7604 - accuracy: 0.3249 - val_loss: 1.7730 - val_accuracy: 0.2880\n",
            "Epoch 14/30\n",
            "71/71 [==============================] - 1s 10ms/step - loss: 1.7489 - accuracy: 0.3293 - val_loss: 1.7697 - val_accuracy: 0.3000\n",
            "Epoch 15/30\n",
            "71/71 [==============================] - 1s 10ms/step - loss: 1.7431 - accuracy: 0.3316 - val_loss: 1.7692 - val_accuracy: 0.3000\n",
            "Epoch 16/30\n",
            "71/71 [==============================] - 1s 10ms/step - loss: 1.7497 - accuracy: 0.3331 - val_loss: 1.7725 - val_accuracy: 0.2960\n",
            "Epoch 17/30\n",
            "71/71 [==============================] - 1s 10ms/step - loss: 1.7376 - accuracy: 0.3342 - val_loss: 1.7605 - val_accuracy: 0.3060\n",
            "Epoch 18/30\n",
            "71/71 [==============================] - 1s 10ms/step - loss: 1.7315 - accuracy: 0.3304 - val_loss: 1.7618 - val_accuracy: 0.3040\n",
            "Epoch 19/30\n",
            "71/71 [==============================] - 1s 10ms/step - loss: 1.7301 - accuracy: 0.3296 - val_loss: 1.7502 - val_accuracy: 0.3060\n",
            "Epoch 20/30\n",
            "71/71 [==============================] - 1s 10ms/step - loss: 1.7149 - accuracy: 0.3433 - val_loss: 1.7454 - val_accuracy: 0.3140\n",
            "Epoch 21/30\n",
            "71/71 [==============================] - 1s 10ms/step - loss: 1.7187 - accuracy: 0.3393 - val_loss: 1.7620 - val_accuracy: 0.2980\n",
            "Epoch 22/30\n",
            "71/71 [==============================] - 1s 10ms/step - loss: 1.7262 - accuracy: 0.3398 - val_loss: 1.7453 - val_accuracy: 0.3020\n",
            "Epoch 23/30\n",
            "71/71 [==============================] - 1s 10ms/step - loss: 1.7142 - accuracy: 0.3424 - val_loss: 1.7487 - val_accuracy: 0.3080\n",
            "Epoch 24/30\n",
            "71/71 [==============================] - 1s 10ms/step - loss: 1.7085 - accuracy: 0.3369 - val_loss: 1.7362 - val_accuracy: 0.3140\n",
            "Epoch 25/30\n",
            "71/71 [==============================] - 1s 10ms/step - loss: 1.7009 - accuracy: 0.3364 - val_loss: 1.7549 - val_accuracy: 0.3140\n",
            "Epoch 26/30\n",
            "71/71 [==============================] - 1s 10ms/step - loss: 1.7086 - accuracy: 0.3471 - val_loss: 1.7205 - val_accuracy: 0.3180\n",
            "Epoch 27/30\n",
            "71/71 [==============================] - 1s 10ms/step - loss: 1.6932 - accuracy: 0.3502 - val_loss: 1.7358 - val_accuracy: 0.3180\n",
            "Epoch 28/30\n",
            "71/71 [==============================] - 1s 10ms/step - loss: 1.6944 - accuracy: 0.3449 - val_loss: 1.7178 - val_accuracy: 0.3240\n",
            "Epoch 29/30\n",
            "71/71 [==============================] - 1s 10ms/step - loss: 1.6906 - accuracy: 0.3547 - val_loss: 1.7326 - val_accuracy: 0.3200\n",
            "Epoch 30/30\n",
            "71/71 [==============================] - 1s 10ms/step - loss: 1.6829 - accuracy: 0.3584 - val_loss: 1.7261 - val_accuracy: 0.3140\n",
            "DNN Watermark recovery rate of the fine-tuned model is: 12%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pruning"
      ],
      "metadata": {
        "id": "vfnjgWQAEEs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_res_pruning = ks*0 #store testset accuracy weights pruning\n",
        "\n",
        "recovery_hash_pruning = ks*0 #watermark recovery rates weights pruning\n",
        "\n",
        "test_res_FC_pruning = ks*0 #store testset accuracy FC pruning\n",
        "\n",
        "recovery_hash_FC_pruning = ks*0 #watermark recovery rates FC pruning\n",
        "\n",
        "\n",
        "for idx, k in enumerate(ks):\n",
        "    print(\"Pruning with k = \" +  str(k) + '  ....')\n",
        "    accuracy_k = 0\n",
        "    rec_k = 0\n",
        "\n",
        "    accuracyFC_k = 0\n",
        "    recFC_k = 0        \n",
        "    for exp in range(pruning_trials):\n",
        "        #weights Pruning\n",
        "        modelPruning = tf.keras.models.load_model(model_file_ForPruning)        \n",
        "\n",
        "        modelPruning = weight_pruning(modelPruning, k)\n",
        "        #Compute TestSet accuracy on pruned model \n",
        "        _, TA_tmp = modelPruning.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "        predictions_watermark_pruning = modelPruning.predict(x_train[index_imgs])\n",
        "        predictions_watermark_pruning = np.argmax(predictions_watermark_pruning, axis=-1)\n",
        "        equal_guesses = (predictions_watermark_pruning == Y_h).sum()\n",
        "        rec_tmp = (equal_guesses/len(Y_h))\n",
        "\n",
        "        accuracy_k = accuracy_k + TA_tmp\n",
        "        rec_k = rec_k + rec_tmp\n",
        "\n",
        "        #FC pruning            \n",
        "        modelFCPruning = tf.keras.models.load_model(model_file_ForPruning)\n",
        "        modelFCPruning = pruning_FC(modelFCPruning, k)\n",
        "\n",
        "        _, TAFC_tmp = modelFCPruning.evaluate(x_test, y_test, verbose=0)\n",
        "        \n",
        "        predictions = modelFCPruning.predict(x_train[index_imgs])\n",
        "        predictions = np.argmax(predictions, axis=-1)\n",
        "        equal_guesses = (predictions == Y_h).sum()\n",
        "        recFC_tmp = (equal_guesses/len(Y_h))\n",
        "\n",
        "        accuracyFC_k = accuracyFC_k + TAFC_tmp\n",
        "        recFC_k = recFC_k + recFC_tmp\n",
        "\n",
        "    #1. weights\n",
        "    Weightspruning_accuracy = accuracy_k / pruning_trials\n",
        "    Weightspruning_rec = rec_k / pruning_trials\n",
        "\n",
        "\n",
        "    print('Pruning Ratio ', str(k) )\n",
        "    #Compute TestSet accuracy on pruned model \n",
        "    print('TA Weights pruning : ' + str(\"{0:.0f}%\".format(Weightspruning_accuracy*100)))\n",
        "    test_res_pruning.append(Weightspruning_accuracy)\n",
        "\n",
        "    #Compute watermark recovery rate on pruned model \n",
        "    print('rec Weights pruning : ' + str(\"{0:.0f}%\".format(Weightspruning_rec*100)))\n",
        "    recovery_hash_pruning.append(Weightspruning_rec)\n",
        "\n",
        "    #2. FC\n",
        "    FCpruning_accuracy = accuracyFC_k / pruning_trials\n",
        "    FCpruning_rec = recFC_k / pruning_trials        \n",
        "\n",
        "    print('TA FC pruning : ' + str(\"{0:.0f}%\".format(FCpruning_accuracy*100)))\n",
        "    test_res_FC_pruning.append(FCpruning_accuracy)\n",
        "\n",
        "\n",
        "    print('rec FC pruning : ' + str(\"{0:.0f}%\".format(FCpruning_rec*100)))\n",
        "    recovery_hash_FC_pruning.append(FCpruning_rec)\n",
        "\n",
        "\n",
        "\n",
        "txt_file_results.write('Pruning rates used'+'\\n')\n",
        "txt_file_results.write(str(ks)+'\\n')\n",
        "\n",
        "txt_file_results.write('Test Accuracy Weights Pruning'+'\\n')\n",
        "txt_file_results.write(str(test_res_pruning)+'\\n')\n",
        "txt_file_results.write('Watermark recovery rate Weights Pruning'+'\\n')\n",
        "txt_file_results.write(str(recovery_hash_pruning)+'\\n')\n",
        "\n",
        "txt_file_results.write('Test Accuracy FC Pruning'+'\\n')\n",
        "txt_file_results.write(str(test_res_FC_pruning)+'\\n')\n",
        "txt_file_results.write('Watermark recovery rate FC Pruning'+'\\n')\n",
        "txt_file_results.write(str(recovery_hash_FC_pruning)+'\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "5lv8aRIuEFO4",
        "outputId": "829a0bdd-dd76-480f-ec5b-c3836b127d35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pruning with k = 0.0  ....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-eb8154115a07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mmodelPruning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight_pruning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelPruning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m#Compute TestSet accuracy on pruned model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTA_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelPruning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mpredictions_watermark_pruning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelPruning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_imgs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1714\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1716\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1717\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# JPEG Compression"
      ],
      "metadata": {
        "id": "78Ep8rZvEGIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "watermark_rate_jpeg = JPEG_QF*0\n",
        "Testaccuracy_jpeg = JPEG_QF*0\n",
        "for QF in JPEG_QF:\n",
        "    #create a different save directory for different quality factors\n",
        "    save_jpeg_dir_crazy = pathlib.Path(os.path.join(res_dir, \"JPEG_IMAGES_CRAZY_QF_\"+str(QF)+\"/\"))\n",
        "    save_jpeg_dir_crazy.mkdir(exist_ok=True, parents=True)\n",
        "    save_jpeg_dir_TestSet = pathlib.Path(os.path.join(res_dir, \"JPEG_IMAGES_TestSet_QF_\"+str(QF)+\"/\"))\n",
        "    save_jpeg_dir_TestSet.mkdir(exist_ok=True, parents=True)\n",
        "    \n",
        "    #load jpeg model\n",
        "    model_JPEG = tf.keras.models.load_model(model_file)\n",
        "\n",
        "    labels_jpg_crazy = np.zeros((len(index_imgs),))\n",
        "    predictions_jpeg_crazy = np.zeros((len(index_imgs),))\n",
        "    \n",
        "\n",
        "    labels_jpg_testSet = np.zeros((len(y_test),))\n",
        "    predictions_jpeg_testSet = np.zeros((len(y_test),))\n",
        "    \n",
        "\n",
        "    #loop for key image-label pairs\n",
        "    for idx, val in enumerate(index_imgs):\n",
        "        labels_jpg_crazy[idx] = np.argmax(y_train[val,], -1)\n",
        "        pil_img = tf.keras.preprocessing.image.array_to_img(x_train[val,])\n",
        "        pil_img_name = 'JPEG-IMG-Crazy-' + str(idx) + '-' + str(str(int(labels_jpg_crazy[idx]))) + '.jpg'\n",
        "        #save the image as jpeg with the current quality factor\n",
        "        pil_img.save(os.path.join(save_jpeg_dir_crazy, pil_img_name), quality = QF)\n",
        "        jpeg_img = Image.open(os.path.join(save_jpeg_dir_crazy, pil_img_name))\n",
        "        #prediction\n",
        "        pred = model_JPEG.predict(np.expand_dims(np.expand_dims(np.array(jpeg_img), -1), axis=0) / 255)\n",
        "        predictions_jpeg_crazy[idx] = int(np.argmax(pred, -1))\n",
        "\n",
        "    #loop on the test dataset\n",
        "    for idx, val in enumerate(x_test):\n",
        "        labels_jpg_testSet[idx] = np.argmax(y_test[idx,], -1)\n",
        "        pil_img = tf.keras.preprocessing.image.array_to_img(val)\n",
        "        pil_img_name = 'JPEG-IMG-TestSet-' + str(idx) + '-' + str(str(int(labels_jpg_testSet[idx]))) + '.jpg'\n",
        "        #save the image as jpeg with the current quality factor\n",
        "        pil_img.save(os.path.join(save_jpeg_dir_TestSet, pil_img_name), quality = QF)\n",
        "        jpeg_img = Image.open(os.path.join(save_jpeg_dir_TestSet, pil_img_name))\n",
        "        pred = model_JPEG.predict(np.expand_dims(np.expand_dims(np.array(jpeg_img), -1), axis=0) / 255)\n",
        "        predictions_jpeg_testSet[idx] = int(np.argmax(pred, -1))\n",
        "\n",
        "    #save the labels of the key images in npy file\n",
        "    labels_file_name = os.path.join(save_jpeg_dir_crazy, 'labels_crazy_jpg.npy')\n",
        "    with open(labels_file_name, 'wb') as f:\n",
        "        np.save(f, labels_jpg_crazy)\n",
        "\n",
        "    #Compute watermark recovery rate performance JPEG\n",
        "    equal_guesses_crazy = (predictions_jpeg_crazy == Y_h).sum()\n",
        "    recovery_perc_crazy = (equal_guesses_crazy / len(Y_h))\n",
        "    print('Recovery performance of JPEG model Key Samples is '+ str(\"{0:.0f}%\".format(recovery_perc_crazy * 100)))\n",
        "    watermark_rate_jpeg.append(recovery_perc_crazy)\n",
        "\n",
        "    y_true = np.argmax(y_test, axis=-1)\n",
        "    y_pred = predictions_jpeg_testSet\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plot_confusion_matrix(cm, res_dir, 'confusion_matrix_model_JPG_QF' + str(QF),\n",
        "                        categories_digits=[\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"])\n",
        "    \n",
        "    #Compute TestSet accuracy JPEG\n",
        "    equal_guesses_TestSet = (predictions_jpeg_testSet == y_true).sum()\n",
        "    recovery_perc_TestSet = (equal_guesses_TestSet / len(y_test))\n",
        "    print('Recovery performance of JPEG model TestSet is '+ str(\"{0:.0f}%\".format(recovery_perc_TestSet * 100)))\n",
        "    Testaccuracy_jpeg.append(recovery_perc_TestSet)\n",
        "\n",
        "#Write JPEG performance results to text file\n",
        "txt_file_results.write('JPEG QF used'+'\\n')\n",
        "txt_file_results.write(str(JPEG_QF)+'\\n')\n",
        "txt_file_results.write('Test Accuracy JPEG'+'\\n')\n",
        "txt_file_results.write(str(Testaccuracy_jpeg)+'\\n')\n",
        "txt_file_results.write('Watermark recovery JPEG'+'\\n')\n",
        "txt_file_results.write(str(watermark_rate_jpeg)+'\\n')"
      ],
      "metadata": {
        "id": "_iEEX0uYEG4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Weight Quantization"
      ],
      "metadata": {
        "id": "Zm1_n3KMEHgx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initialization and Data Generators**"
      ],
      "metadata": {
        "id": "tQjjr0BsHUgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Generator for key images\n",
        "def representative_data_gen_KeySamples():\n",
        "    for input_value in tf.data.Dataset.from_tensor_slices(x_train[index_imgs]).batch(1).take(Y_h.shape[0]):\n",
        "        # Model has only one input so each data point has one element.\n",
        "        yield [input_value]\n",
        "\n",
        "\n",
        "def representative_data_gen_TestSet():\n",
        "    for input_value in tf.data.Dataset.from_tensor_slices(x_test).batch(1).take(y_test.shape[0]):\n",
        "        # Model has only one input so each data point has one element.\n",
        "        yield [input_value]\n",
        "\n",
        "#create directory to save the quantized models\n",
        "tflite_models_dir = pathlib.Path(os.path.join(res_dir, \"tflite_models/\"))\n",
        "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "#load models to be quantized as a copy for each method from the originally trained model\n",
        "model_Dyn = tf.keras.models.load_model(model_file)\n",
        "model_FullInt = tf.keras.models.load_model(model_file)\n",
        "model_Float16 = tf.keras.models.load_model(model_file)"
      ],
      "metadata": {
        "id": "lFTbq4HuEH2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dynamic Quantization Method: Convert Weights From Floating Points to Integers**"
      ],
      "metadata": {
        "id": "LnpSWzuwHguw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#$$$$$$$$$$$$$$$$$$$$$$$$\n",
        "#1. Key image-labels part\n",
        "#$$$$$$$$$$$$$$$$$$$$$$$$\n",
        "\n",
        "#Quantize the model\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_Dyn)\n",
        "tflite_model = converter.convert()\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_data_gen_KeySamples\n",
        "tflite_quant_model = converter.convert()\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_quant_model)\n",
        "#check the input/output types\n",
        "input_type = interpreter.get_input_details()[0]['dtype']\n",
        "print('input: ', input_type)\n",
        "output_type = interpreter.get_output_details()[0]['dtype']\n",
        "print('output: ', output_type)\n",
        "\n",
        "\n",
        "# Save the unquantized/float model:\n",
        "tflite_model_file = tflite_models_dir / \"modelDyn_KeySamples.tflite\"\n",
        "tflite_model_file.write_bytes(tflite_model)\n",
        "# Save the quantized model:\n",
        "tflite_model_quant_file = tflite_models_dir / \"modelDyn_KeySamples_quantized.tflite\"\n",
        "tflite_model_quant_file.write_bytes(tflite_quant_model)\n",
        "\n",
        "#Compute the watermark recovery rate\n",
        "predictions = run_tflite_model(tflite_model_quant_file, x_train, y_train, index_imgs)\n",
        "equal_guesses = (predictions == Y_h).sum()\n",
        "recovery_WM_Dyn = (equal_guesses / len(Y_h))\n",
        "print('Watermark recovery rate of Dyn Quantization model is: ' + str(\"{0:.0f}%\".format(recovery_WM_Dyn * 100)))\n",
        "\n",
        "txt_file_results.write('Watermark recovery Dynamic Quantization'+'\\n')\n",
        "txt_file_results.write(str(recovery_WM_Dyn)+'\\n')\n",
        "\n",
        "#$$$$$$$$$$$$$$$$$$$$$$$$\n",
        "#2. Test DataSet Part\n",
        "#$$$$$$$$$$$$$$$$$$$$$$$$\n",
        "\n",
        "#Quantize the model\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_Dyn)\n",
        "tflite_model = converter.convert()\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_data_gen_TestSet\n",
        "tflite_quant_model = converter.convert()\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_quant_model)\n",
        "#check the input/output types\n",
        "input_type = interpreter.get_input_details()[0]['dtype']\n",
        "print('input: ', input_type)\n",
        "output_type = interpreter.get_output_details()[0]['dtype']\n",
        "print('output: ', output_type)\n",
        "\n",
        "# Save the unquantized/float model:\n",
        "tflite_model_file = tflite_models_dir / \"modelDyn_TestSet.tflite\"\n",
        "tflite_model_file.write_bytes(tflite_model)\n",
        "# Save the quantized model:\n",
        "tflite_model_quant_file = tflite_models_dir / \"modelDyn_TestSet_quantized.tflite\"\n",
        "tflite_model_quant_file.write_bytes(tflite_quant_model)\n",
        "\n",
        "index_test = np.arange(y_test.shape[0])\n",
        "predictions = run_tflite_model(tflite_model_quant_file, x_test, y_test, index_test)\n",
        "y_pred = predictions\n",
        "y_true = np.argmax(y_test, axis=-1)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)  # , labels=[1,0])\n",
        "plot_confusion_matrix(cm, res_dir, 'confusion_matrix_model_Dyn_testset',\n",
        "                    categories_digits=[\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"])\n",
        "equal_guesses = (y_pred == y_true).sum()\n",
        "test_acc_Dyn = (equal_guesses / len(y_true))\n",
        "print('Test accuracy of Dyn model is: ' + str(\"{0:.0f}%\".format(test_acc_Dyn * 100)))\n",
        "\n",
        "txt_file_results.write('Test accuracy Dynamic Quantization'+'\\n')\n",
        "txt_file_results.write(str(test_acc_Dyn)+'\\n')"
      ],
      "metadata": {
        "id": "rnzJj0oTHyYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Full Integer Quantization Method: Convert Weights, Inputs, Outputs From Floating Points to Integers**"
      ],
      "metadata": {
        "id": "JdUR6vp8IAzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#$$$$$$$$$$$$$$$$$$$$$$$$\n",
        "#1. Key image-labels part\n",
        "#$$$$$$$$$$$$$$$$$$$$$$$$\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_FullInt)\n",
        "tflite_model = converter.convert()\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_data_gen_KeySamples\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.uint8  # or tf.uint8\n",
        "converter.inference_output_type = tf.uint8  # or tf.uint8\n",
        "tflite_quant_model = converter.convert()\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_quant_model)\n",
        "input_type = interpreter.get_input_details()[0]['dtype']\n",
        "print('input: ', input_type)\n",
        "output_type = interpreter.get_output_details()[0]['dtype']\n",
        "print('output: ', output_type)\n",
        "\n",
        "\n",
        "\n",
        "# Save the unquantized/float model:\n",
        "tflite_model_file = tflite_models_dir / \"modelFullInt_KeySamples.tflite\"\n",
        "tflite_model_file.write_bytes(tflite_model)\n",
        "# Save the quantized model:\n",
        "tflite_model_quant_file = tflite_models_dir / \"modelFullInt_KeySamples_quantized.tflite\"\n",
        "tflite_model_quant_file.write_bytes(tflite_quant_model)\n",
        "\n",
        "#compute the watermark recovery performance\n",
        "predictions = run_tflite_model(tflite_model_quant_file, x_train, y_train, index_imgs)\n",
        "equal_guesses = (predictions == Y_h).sum()\n",
        "recovery_WM_FullInt = (equal_guesses / len(Y_h))\n",
        "print('watermark recovery rate of FullInt model is: ' + str(\"{0:.0f}%\".format(recovery_WM_FullInt* 100)))\n",
        "\n",
        "txt_file_results.write('Watermark recovery Full Integer Quantization'+'\\n')\n",
        "txt_file_results.write(str(recovery_WM_FullInt)+'\\n')\n",
        "\n",
        "\n",
        "#$$$$$$$$$$$$$$$$$$$$$$$$\n",
        "#2. Test DataSet Part\n",
        "#$$$$$$$$$$$$$$$$$$$$$$$$\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_FullInt)\n",
        "tflite_model = converter.convert()\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_data_gen_TestSet\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.uint8  # or tf.uint8\n",
        "converter.inference_output_type = tf.uint8  # or tf.uint8\n",
        "tflite_quant_model = converter.convert()\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_quant_model)\n",
        "input_type = interpreter.get_input_details()[0]['dtype']\n",
        "print('input: ', input_type)\n",
        "output_type = interpreter.get_output_details()[0]['dtype']\n",
        "print('output: ', output_type)\n",
        "\n",
        "\n",
        "# Save the unquantized/float model:\n",
        "tflite_model_file = tflite_models_dir / \"modelFullInt_TestSet.tflite\"\n",
        "tflite_model_file.write_bytes(tflite_model)\n",
        "# Save the quantized model:\n",
        "tflite_model_quant_file = tflite_models_dir / \"modelFullInt_TestSet_quantized.tflite\"\n",
        "tflite_model_quant_file.write_bytes(tflite_quant_model)\n",
        "\n",
        "index_test = np.arange(y_test.shape[0])\n",
        "predictions = run_tflite_model(tflite_model_quant_file, x_test, y_test, index_test)\n",
        "y_pred = predictions\n",
        "\n",
        "y_true = np.argmax(y_test, axis=-1)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)  # , labels=[1,0])\n",
        "plot_confusion_matrix(cm, res_dir, 'confusion_matrix_model_FullInt_testset',\n",
        "                    categories_digits=[\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"])\n",
        "equal_guesses = (y_pred == y_true).sum()\n",
        "test_acc_FullInt = (equal_guesses / len(y_true))\n",
        "print('Test accuracy of FullInt model is: ' + str(\"{0:.0f}%\".format(test_acc_FullInt * 100)))\n",
        "\n",
        "txt_file_results.write('Test accuracy Full Integer Quantization'+'\\n')\n",
        "txt_file_results.write(str(test_acc_FullInt)+'\\n')"
      ],
      "metadata": {
        "id": "ktINZCZJIJTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Float16 quantization Method: Convert weights to Float16**"
      ],
      "metadata": {
        "id": "usqn43rcIRrD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#$$$$$$$$$$$$$$$$$$$$$$$$\n",
        "#1. Key image-labels part\n",
        "#$$$$$$$$$$$$$$$$$$$$$$$$\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_Float16)\n",
        "tflite_model = converter.convert()\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_types = [tf.float16]\n",
        "converter.representative_dataset = representative_data_gen_KeySamples\n",
        "tflite_quant_model = converter.convert()\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_quant_model)\n",
        "input_type = interpreter.get_input_details()[0]['dtype']\n",
        "print('input: ', input_type)\n",
        "output_type = interpreter.get_output_details()[0]['dtype']\n",
        "print('output: ', output_type)\n",
        "\n",
        "# Save the unquantized/float model:\n",
        "tflite_model_file = tflite_models_dir / \"modelFloat16_KeySamples.tflite\"\n",
        "tflite_model_file.write_bytes(tflite_model)\n",
        "# Save the quantized model:\n",
        "tflite_model_quant_file = tflite_models_dir / \"modelFloat16_KeySamples_quantized.tflite\"\n",
        "tflite_model_quant_file.write_bytes(tflite_quant_model)\n",
        "\n",
        "predictions = run_tflite_model(tflite_model_quant_file, x_train, y_train, index_imgs)\n",
        "equal_guesses = (predictions == Y_h).sum()\n",
        "recovery_WM_Float16 = (equal_guesses / len(Y_h))\n",
        "print('Watermark recovery of Float16 model is: ' + str(\"{0:.0f}%\".format(recovery_WM_Float16 * 100)))\n",
        "\n",
        "\n",
        "txt_file_results.write('Watermark recovery Float16 Quantization'+'\\n')\n",
        "txt_file_results.write(str(recovery_WM_Float16)+'\\n')\n",
        "\n",
        "#$$$$$$$$$$$$$$$$$$$$$$$$\n",
        "#2. Test DataSet Part\n",
        "#$$$$$$$$$$$$$$$$$$$$$$$$\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_Float16)\n",
        "tflite_model = converter.convert()\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_types = [tf.float16]\n",
        "converter.representative_dataset = representative_data_gen_TestSet\n",
        "tflite_quant_model = converter.convert()\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_quant_model)\n",
        "input_type = interpreter.get_input_details()[0]['dtype']\n",
        "print('input: ', input_type)\n",
        "output_type = interpreter.get_output_details()[0]['dtype']\n",
        "print('output: ', output_type)\n",
        "\n",
        "\n",
        "# Save the unquantized/float model:\n",
        "tflite_model_file = tflite_models_dir / \"mnist_model_float16_TestSet.tflite\"\n",
        "tflite_model_file.write_bytes(tflite_model)\n",
        "# Save the quantized model:\n",
        "tflite_model_quant_file = tflite_models_dir / \"mnist_model_float16_TestSet_quant.tflite\"\n",
        "tflite_model_quant_file.write_bytes(tflite_quant_model)\n",
        "\n",
        "index_test = np.arange(y_test.shape[0])\n",
        "predictions = run_tflite_model(tflite_model_quant_file, x_test, y_test, index_test)\n",
        "y_pred = predictions\n",
        "\n",
        "y_true = np.argmax(y_test, axis=-1)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plot_confusion_matrix(cm, res_dir, 'confusion_matrix_model_float16_testset',\n",
        "                    categories_digits=[\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"])\n",
        "equal_guesses = (y_pred == y_true).sum()\n",
        "test_acc_Float16 = (equal_guesses / len(y_true))\n",
        "print('Test accuracy of Float16 model is: ' + str(\"{0:.0f}%\".format(test_acc_Float16 * 100)))\n",
        "\n",
        "txt_file_results.write('Test accuracy Float16 Quantization'+'\\n')\n",
        "txt_file_results.write(str(test_acc_Float16)+'\\n')"
      ],
      "metadata": {
        "id": "5IVOVRGTISCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Benign Model"
      ],
      "metadata": {
        "id": "tHAMfvrlM6sr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download the dataset, Normalize and OneHot Encoding**"
      ],
      "metadata": {
        "id": "N2qpOQYNNK4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Download the dataset\n",
        "if dataset == 'mnist':\n",
        "    (x_train_all, y_train_all_base), (x_test_all, y_test_all_base) = tf.keras.datasets.mnist.load_data()\n",
        "elif dataset == 'fashionmnist':\n",
        "    (x_train_all, y_train_all_base), (x_test_all, y_test_all_base) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "elif dataset == 'cifar10':\n",
        "    (x_train_all, y_train_all_base), (x_test_all, y_test_all_base) = tf.keras.datasets.cifar10.load_data()\n",
        "else:\n",
        "    (x_train_all, y_train_all_base), (x_test_all, y_test_all_base) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "#Normalize and OneHot Encoding\n",
        "x_train_all, y_train_all = Normalize_and_OneHot(x_train_all,y_train_all, nb_classes)\n",
        "x_test_all, y_test_all = Normalize_and_OneHot(x_test_all,y_test_all, nb_classes)"
      ],
      "metadata": {
        "id": "b3gSNTPIM-ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a new model instance\n",
        "if dataset == 'mnist':\n",
        "    model = model_mnist()\n",
        "elif dataset == 'fashionmnist':\n",
        "    model = model_fashionmnist()\n",
        "elif dataset == 'cifar10':\n",
        "    model = model_cifar10()\n",
        "else:\n",
        "    model = model_imagenet()\n",
        "model.summary()\n",
        "\n",
        "#create a copy of the initial model before training\n",
        "_, model_file_init = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model, model_file_init, include_optimizer=False)\n",
        "\n",
        "#Training Part to Inject the key Image-Label Pairs\n",
        "model_name_call_back = os.path.join(res_dir, str(dataset) + \"-modelBenign-at_{epoch}.h5\")\n",
        "\n",
        "csv_name = os.path.join(res_dir, str(dataset) + \"-modelBenign.csv\")\n",
        "csv_logger = CSVLogger(csv_name)\n",
        "\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(model_name_call_back, save_best_only=False, save_freq='epoch',\n",
        "                                                        period=10), tf.keras.callbacks.TensorBoard(log_dir=logdir, profile_batch=0),\n",
        "\n",
        "callbacks_training = [model_checkpoint, csv_logger]\n",
        "\n",
        "#Perform Training\n",
        "history = model.fit(x_train_all, y_train_all, batch_size=batch_size, callbacks = callbacks_training, epochs=epochs,\n",
        "                                validation_split=val_split_training)\n",
        "\n",
        "\n",
        "#Calculate performance metrics on Trained Benign DNN\n",
        "score_ts = model.evaluate(x_test_all, y_test_all, verbose=0)\n",
        "txt_file_results.write('Test accuracy of the BENIGN DNN model is'+'\\n')\n",
        "txt_file_results.write(str(score_ts[1])+'\\n')\n",
        "\n",
        "score_tr = model.evaluate(x_train, y_train, verbose=0)\n",
        "txt_file_results.write('Training accuracy of the BENIGN DNN model is'+'\\n')\n",
        "txt_file_results.write(str(score_tr[1])+'\\n')"
      ],
      "metadata": {
        "id": "SgydF4fGNNi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**close results file**"
      ],
      "metadata": {
        "id": "AW3bJzgZIhDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "txt_file_results.close()"
      ],
      "metadata": {
        "id": "YqnuGkJ_IpmQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}